{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for Korean Movie Review Data\n",
    "\n",
    "- 이번에는 같은 Bag of Words 모델이지만, 단어를 100차원에 embedding한 뒤 풀어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:06:48.709865Z",
     "start_time": "2018-11-20T06:06:48.679918Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"movie_data.pickle\", \"rb\") as f:\n",
    "    movie_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:06:49.671979Z",
     "start_time": "2018-11-20T06:06:49.660010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reviews', 'scores', 'reviews_ix', 'word2ix', 'ix2word', 'max_seq_length'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:06:50.278682Z",
     "start_time": "2018-11-20T06:06:50.274664Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = movie_data[\"reviews\"]\n",
    "scores = movie_data[\"scores\"]\n",
    "reviews_ix = movie_data[\"reviews_ix\"]\n",
    "word2ix = movie_data[\"word2ix\"]\n",
    "ix2word = movie_data[\"ix2word\"]\n",
    "max_seq_length = movie_data[\"max_seq_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Trian / Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:06:53.483065Z",
     "start_time": "2018-11-20T06:06:53.475087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "# 리뷰 문장의 길이를 max_seq_length에 맞춰주고 빈 공간에는 <PAD>를 넣어 줍니다.\n",
    "def pad_sequence(seq, max_seq_length):\n",
    "    if len(seq) < max_seq_length:\n",
    "        seq += [word2ix.get(\"<PAD>\")]*(max_seq_length-len(seq))\n",
    "    return seq\n",
    "\n",
    "print(len(reviews_ix[0]))\n",
    "print(len(pad_sequence(reviews_ix[0], max_seq_length)))\n",
    "\n",
    "reviews_ix = [pad_sequence(reviews_ix[i], max_seq_length) for i in range(len(reviews_ix))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:06:59.237670Z",
     "start_time": "2018-11-20T06:06:56.005319Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_ix, \n",
    "                                                    scores, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:06:59.400236Z",
     "start_time": "2018-11-20T06:06:59.394254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:07:01.439782Z",
     "start_time": "2018-11-20T06:07:01.434795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:07:02.002308Z",
     "start_time": "2018-11-20T06:07:01.996294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "#### 2. BoW + nn.Embedding\n",
    "https://github.com/Chogyuwon/PyTorch_Fast_Campus_2018/blob/master/week6/2_Embedding_basic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:07:06.318727Z",
     "start_time": "2018-11-20T06:07:04.491615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x223db7d8710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "#from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:07:11.508844Z",
     "start_time": "2018-11-20T06:07:11.503858Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:07:12.453354Z",
     "start_time": "2018-11-20T06:07:12.445374Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1512,\n",
       " 2279,\n",
       " 1491,\n",
       " 4296,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:07:20.469871Z",
     "start_time": "2018-11-20T06:07:20.462889Z"
    }
   },
   "outputs": [],
   "source": [
    "class BoW_Clf_Embed_mean(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, output_size):\n",
    "        super(BoW_Clf_Embed_mean, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size,\n",
    "                                  embedding_size,\n",
    "                                  padding_idx=word2ix.get(\"<PAD>\"))  \n",
    "        \n",
    "        self.linear = nn.Linear(embedding_size, output_size)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        embed = self.embed(inputs)\n",
    "        # 각 임베딩 차원의 평균 값을 가져옵니다. \n",
    "        # ex) torch.mean(torch.Tensor([[0,0,1,0],[0,1,0,0]]),1) = tensor([0.25,0.25])\n",
    "        # 100차원의 값 113개를 각각 평균해서 113차원의 값 1개로 가져옵니다. \n",
    "        # 해당되는 각 단어를 100차원으로 embedding하고 그 값을 평균내서 1개의 값으로 만듭니다.\n",
    "        # 최대 문장의 길이가 113개 이므로 이런 값이 113개 나오고 이 값으로 분류를 합니다.\n",
    "        embed_mean = torch.mean(embed, 1)\n",
    "        \n",
    "        out = self.linear(embed_mean)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:17:13.438531Z",
     "start_time": "2018-11-20T06:17:13.428594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.2500])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.Tensor([[0,0,1,0],[0,1,0,0]]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:28:46.312638Z",
     "start_time": "2018-11-20T06:20:27.229098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.386758804321289\n",
      "2.0446617603302\n",
      "2.0384373664855957\n",
      "2.033135175704956\n",
      "2.027993679046631\n",
      "2.0229556560516357\n",
      "2.018003463745117\n",
      "2.0131256580352783\n",
      "2.0083093643188477\n",
      "2.0035412311553955\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "LR = 0.01\n",
    "\n",
    "model = BoW_Clf_Embed_mean(len(word2ix),100, 11).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=LR, momentum=0.9)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.zero_grad()\n",
    "    inputs = torch.LongTensor(X_train).to(device)\n",
    "    targets = torch.LongTensor(y_train).to(device)\n",
    "    \n",
    "    preds = model(inputs)\n",
    "    \n",
    "    loss = loss_function(preds, targets)\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T06:30:04.171251Z",
     "start_time": "2018-11-20T06:30:04.097450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : ['후반/Noun', '쫄렸다/Noun']\n",
      "Prediction : 10\n",
      "Truth : 9\n",
      "\n",
      "\n",
      "Input : ['감동/Noun', '영화/Noun', '보고/Noun', '운/Noun', '거의/Noun', '애니메이션/Noun', '보면서/Verb', '울줄/Verb', '몰랐네요/Verb', 'ㅜ/KoreanParticle', '감동/Noun', 'ㅜㅜ/KoreanParticle']\n",
      "Prediction : 10\n",
      "Truth : 10\n",
      "\n",
      "\n",
      "Input : ['스토리/Noun', '별로/Noun', '노래/Noun']\n",
      "Prediction : 10\n",
      "Truth : 8\n",
      "\n",
      "\n",
      "Input : ['히어로/Noun', '물/Noun', '찍어도/Verb', '될/Verb', '정도/Noun', '그래픽/Noun', '본/Verb', '한국영/Noun', '화의/Noun', '희망/Noun', '이야기/Noun', '거기/Noun']\n",
      "Prediction : 10\n",
      "Truth : 5\n",
      "\n",
      "\n",
      "Input : ['보통/Noun', '서로/Noun', '아는/Verb', '상황/Noun', '주먹/Noun', '메/Noun', '쳐서/Verb', '다른/Noun', '격방/Noun', '시도/Noun', '하는게/Verb', '정상/Noun', '로메/Noun', '쳐/Verb', '대는게/Verb', '인상/Noun', '또/Noun', '와칸/Noun', '다인/Noun', '가에서/Verb', '개때/Noun', '닥치는데/Verb', '굳이/Noun', '칼/Noun', '빼/Noun', '일일이/Noun', '상대/Noun', '하는것도/Verb', '졸/Noun', '인상/Noun', '과거/Noun', '마징/Noun', '가가/Noun', '싸우다가/Verb', '죽기/Verb', '직전/Noun', '가슴/Noun', '원자력/Noun', '빔/Noun', '쏴서/Verb', '이기는거/Verb', '배운듯/Verb']\n",
      "Prediction : 10\n",
      "Truth : 0\n",
      "\n",
      "\n",
      "Input : ['평론가/Noun', '의미/Noun', '평론/Noun', '하지만/Verb', '년/Noun', '동안/Noun', '봐/Verb', '온/Noun', '영화/Noun', '가장/Noun', '눈/Noun', '귀가/Noun', '마음/Noun', '또/Noun', '보고싶다/Verb']\n",
      "Prediction : 10\n",
      "Truth : 10\n",
      "\n",
      "\n",
      "Accuracy : 31.876138433515482\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "model.eval()\n",
    "for i, seq in enumerate(X_test):\n",
    "    \n",
    "    input = torch.LongTensor(seq).view(1,-1).to(device)\n",
    "    pred = model(input)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    true = y_test[i]\n",
    "    \n",
    "    if true == pred.item():\n",
    "        correct +=1\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        input_seq = [ix2word.get(ix) for ix in seq if ix != 0]\n",
    "        print(\"Input :\", input_seq)\n",
    "        print(\"Prediction :\", pred.item())\n",
    "        print(\"Truth :\", y_test[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"Accuracy :\", (correct/len(X_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
