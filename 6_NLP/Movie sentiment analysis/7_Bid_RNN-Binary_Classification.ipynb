{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for Korean Movie Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"movie_data.pickle\", \"rb\") as f:\n",
    "    movie_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reviews', 'scores', 'reviews_ix', 'word2ix', 'ix2word', 'max_seq_length'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = movie_data[\"reviews\"]\n",
    "scores = movie_data[\"scores\"]\n",
    "reviews_ix = movie_data[\"reviews_ix\"]\n",
    "word2ix = movie_data[\"word2ix\"]\n",
    "ix2word = movie_data[\"ix2word\"]\n",
    "max_seq_length = movie_data[\"max_seq_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, score in enumerate(scores):\n",
    "    if score <= 6:\n",
    "        scores[i] = 0\n",
    "    else:\n",
    "        scores[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1138, 0: 689})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Trian / Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "def pad_sequence(seq, max_seq_length):\n",
    "    if len(seq) < max_seq_length:\n",
    "        seq += [word2ix.get(\"<PAD>\")]*(max_seq_length-len(seq))\n",
    "    return seq\n",
    "\n",
    "print(len(reviews_ix[0]))\n",
    "print(len(pad_sequence(reviews_ix[0], max_seq_length)))\n",
    "\n",
    "reviews_ix = [pad_sequence(reviews_ix[i], max_seq_length) for i in range(len(reviews_ix))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_ix, \n",
    "                                                    scores, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "#### 3.4. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(777);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1512,\n",
       " 2279,\n",
       " 1491,\n",
       " 4296,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Clf(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(RNN_Clf, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,\n",
    "                                  embedding_size,\n",
    "                                  padding_idx=word2ix.get(\"<PAD>\"))\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=embedding_size, \n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          batch_first=True,\n",
    "                          bidirectional=bidirectional)\n",
    "              \n",
    "        self.linear = nn.Linear(hidden_size*num_directions, num_classes)\n",
    "                    \n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        embed = self.embed(inputs)\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "        \n",
    "        out, _ = self.rnn(embed, hidden)\n",
    "\n",
    "        return self.linear(out[:, -1:, :].squeeze(1))\n",
    "\n",
    "    def predict(self,inputs):\n",
    "        hidden = self.init_hidden(1)\n",
    "        embed = self.embed(inputs)\n",
    "\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "        \n",
    "        out, _ = self.rnn(embed, hidden)\n",
    "\n",
    "        return self.linear(out[:, -1:, :].squeeze(1))\n",
    "\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        return Variable(torch.zeros(num_layers*num_directions, batch_size, hidden_size)).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6978909969329834\n",
      "0.6675363183021545\n",
      "0.6675360202789307\n",
      "0.6675358414649963\n",
      "0.667535662651062\n",
      "0.6675354242324829\n",
      "0.6675352454185486\n",
      "0.6675350069999695\n",
      "0.6675346493721008\n",
      "0.6675344705581665\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5000\n",
    "LR = 0.001\n",
    "hidden_size = max_seq_length\n",
    "num_classes = 2\n",
    "num_layers = 3\n",
    "num_directions = 2\n",
    "bidirectional=True\n",
    "batch_size = len(X_train)\n",
    "\n",
    "model = RNN_Clf(vocab_size = len(word2ix), embedding_size = 300).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=LR, momentum=0.9)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.zero_grad()\n",
    "    inputs = Variable(torch.LongTensor(X_train)).to(device)\n",
    "    targets = Variable(torch.LongTensor(y_train)).to(device)\n",
    "    \n",
    "    preds = model(inputs)\n",
    "    \n",
    "    loss = loss_function(preds, targets)\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : ['후반/Noun', '쫄렸다/Noun']\n",
      "Prediction : 1\n",
      "Truth : 1\n",
      "\n",
      "\n",
      "Input : ['감동/Noun', '영화/Noun', '보고/Noun', '운/Noun', '거의/Noun', '애니메이션/Noun', '보면서/Verb', '울줄/Verb', '몰랐네요/Verb', 'ㅜ/KoreanParticle', '감동/Noun', 'ㅜㅜ/KoreanParticle']\n",
      "Prediction : 1\n",
      "Truth : 1\n",
      "\n",
      "\n",
      "Input : ['스토리/Noun', '별로/Noun', '노래/Noun']\n",
      "Prediction : 1\n",
      "Truth : 1\n",
      "\n",
      "\n",
      "Input : ['히어로/Noun', '물/Noun', '찍어도/Verb', '될/Verb', '정도/Noun', '그래픽/Noun', '본/Verb', '한국영/Noun', '화의/Noun', '희망/Noun', '이야기/Noun', '거기/Noun']\n",
      "Prediction : 1\n",
      "Truth : 0\n",
      "\n",
      "\n",
      "Input : ['보통/Noun', '서로/Noun', '아는/Verb', '상황/Noun', '주먹/Noun', '메/Noun', '쳐서/Verb', '다른/Noun', '격방/Noun', '시도/Noun', '하는게/Verb', '정상/Noun', '로메/Noun', '쳐/Verb', '대는게/Verb', '인상/Noun', '또/Noun', '와칸/Noun', '다인/Noun', '가에서/Verb', '개때/Noun', '닥치는데/Verb', '굳이/Noun', '칼/Noun', '빼/Noun', '일일이/Noun', '상대/Noun', '하는것도/Verb', '졸/Noun', '인상/Noun', '과거/Noun', '마징/Noun', '가가/Noun', '싸우다가/Verb', '죽기/Verb', '직전/Noun', '가슴/Noun', '원자력/Noun', '빔/Noun', '쏴서/Verb', '이기는거/Verb', '배운듯/Verb']\n",
      "Prediction : 1\n",
      "Truth : 0\n",
      "\n",
      "\n",
      "Input : ['평론가/Noun', '의미/Noun', '평론/Noun', '하지만/Verb', '년/Noun', '동안/Noun', '봐/Verb', '온/Noun', '영화/Noun', '가장/Noun', '눈/Noun', '귀가/Noun', '마음/Noun', '또/Noun', '보고싶다/Verb']\n",
      "Prediction : 1\n",
      "Truth : 1\n",
      "\n",
      "\n",
      "Accuracy : 64.66302367941712\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, seq in enumerate(X_test):\n",
    "    input = Variable(torch.LongTensor(seq).view(1,-1)).to(device)\n",
    "    pred = model.predict(input)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    true = y_test[i]\n",
    "    if true == pred.item():\n",
    "        correct +=1\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        input_seq = [ix2word.get(ix) for ix in seq if ix != 0]\n",
    "        print(\"Input :\", input_seq)\n",
    "        print(\"Prediction :\", pred.item())\n",
    "        print(\"Truth :\", y_test[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"Accuracy :\", (correct/len(X_test)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-tf19",
   "language": "python",
   "name": "tf19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
