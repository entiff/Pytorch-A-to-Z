{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: 자동 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autograd 패키지는 tensor의 모든 연산에 자동 미분을 제공합니다. 이는 define-by-run의 프레임워크로 코드를 어떻게 작성하느냐에 따라 역전파가 정의된다는 뜻입니다. 역전파는 학습과정의 매 단계마다 달라집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .requires_grad 속성을 True로 설정하면 해당 tensor의 모든 연산을 추적합니다. 계산이 완료된 후 .backward()를 호출해 gradient를 자동으로 계산할 수 있습니다. 이 tensor의 gradient는 .grad에 누적됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연산 기록을 추적하는 것을 멈추기 위해 코드 블럭을 with torch.no_grad():로 감쌀 수 있습니다. gradient는 필요 없지만 requires_grad=True가 설정되어 학습 가능한 Parameter(매개변수)를 갖는 모델을 평가할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:35.045011Z",
     "start_time": "2018-10-16T12:34:35.041545Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:35.395161Z",
     "start_time": "2018-10-16T12:34:35.390199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2,requires_grad=True) #tensor를 생성하고 requires_grad=True로 연산을 기록합니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:35.683683Z",
     "start_time": "2018-10-16T12:34:35.679238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>)\n"
     ]
    }
   ],
   "source": [
    "y = x+2 #gradient function이 자동으로 포함됩니다.\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:35.979952Z",
     "start_time": "2018-10-16T12:34:35.975984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:36.230040Z",
     "start_time": "2018-10-16T12:34:36.225052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x000002E393F8AE48>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2)\n",
    "a = ((a*3)/(a-1)) \n",
    "print(a.requires_grad)\n",
    "print(a.grad_fn) # 사용자가 만든 텐서의 grad_fn은 none입니다.\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn) #requires_grad_(True)로 지정하고 연산하면 이렇게 grad_fn가 생깁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:37.141890Z",
     "start_time": "2018-10-16T12:34:37.135442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(out) # out = 3(x+2)*2\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:34:37.738725Z",
     "start_time": "2018-10-16T12:34:37.731296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.grad) # d(out)/dx 를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:43:59.822098Z",
     "start_time": "2018-10-16T12:43:59.805731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8602, -2.7999,  1.4120], grad_fn=<MulBackward>) tensor(3.2517)\n",
      "tensor([-1.7205, -5.5999,  2.8239], grad_fn=<MulBackward>) tensor(6.5033)\n",
      "tensor([ -3.4409, -11.1997,   5.6478], grad_fn=<MulBackward>) tensor(13.0066)\n",
      "tensor([ -6.8818, -22.3995,  11.2956], grad_fn=<MulBackward>) tensor(26.0132)\n",
      "tensor([-13.7636, -44.7989,  22.5913], grad_fn=<MulBackward>) tensor(52.0264)\n",
      "tensor([-27.5272, -89.5979,  45.1826], grad_fn=<MulBackward>) tensor(104.0529)\n",
      "tensor([ -55.0545, -179.1958,   90.3652], grad_fn=<MulBackward>) tensor(208.1057)\n",
      "tensor([-110.1090, -358.3915,  180.7303], grad_fn=<MulBackward>) tensor(416.2114)\n",
      "tensor([-220.2180, -716.7831,  361.4607], grad_fn=<MulBackward>) tensor(832.4229)\n",
      "tensor([ -440.4359, -1433.5662,   722.9214], grad_fn=<MulBackward>) tensor(1664.8457)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,requires_grad=True)\n",
    "\n",
    "y=x*2\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    \n",
    "    #data.norm()은 점들 사이의 유클리디안 거리를 나타냅니다\n",
    "    #torch.sqrt(torch.sum(torch.pow(y, 2)))\n",
    "    \n",
    "    y = y*2\n",
    "    \n",
    "    print(y,y.data.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:44:00.141162Z",
     "start_time": "2018-10-16T12:44:00.133745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -440.4359, -1433.5662,   722.9214], grad_fn=<MulBackward>)\n",
      "tensor([ 204.8000, 2048.0000,    0.2048])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1,1.0,0.0001],dtype=torch.float)\n",
    "print(y)\n",
    "y.backward(gradients)\n",
    "print(x.grad) # d(y)/d(x) 를 출력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:47:24.728167Z",
     "start_time": "2018-10-16T12:47:24.724661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad) #tensor들의 연산 기록 추적을 막을 수 있습니다.\n",
    "     \n",
    "print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autograd package에 대한 더 자세한 정보는 다음의 링크를 참고하세요. https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
